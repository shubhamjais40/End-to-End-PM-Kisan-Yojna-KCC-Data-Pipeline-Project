{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6695ce",
   "metadata": {},
   "source": [
    "# Importing python libs and SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac46fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "import pandas as ps\n",
    "from pyspark.sql.functions import trim,upper,lower,to_date,to_timestamp,transform,split,col\n",
    "from pyspark.sql.functions import dayofmonth,month,hour\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.sql.functions import udf,col\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "spark=SparkSession\\\n",
    "           .builder\\\n",
    "           .appName(\"SparkSQLTransformApp\")\\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa26a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.selfDestruct.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabad0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining path for extracts raw files\n",
    "\n",
    "EXTRACTSPATH = Path.cwd().parent/\"extracts\"/\"*.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86727f07",
   "metadata": {},
   "source": [
    "# Reading extracts raw files from extracts directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a97676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_10extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_11extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_12extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_6extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_7extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_8extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_9extracts.xlsx']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_list = glob.glob(str(EXTRACTSPATH))\n",
    "\n",
    "extract_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433aa30",
   "metadata": {},
   "source": [
    "# Reading extracts in chunks and appending all dataframes into empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d5db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_10extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_11extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_12extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_6extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_7extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_8extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_9extracts.xlsx appended...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frame=ps.DataFrame([])\n",
    "for chunks in extract_list:\n",
    "    df=ps.read_excel(chunks,index_col=None)\n",
    "    frame=frame.append(df)\n",
    "    print(f'{chunks} appended...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e74b9c",
   "metadata": {},
   "source": [
    "# Converting Appended pandas Dataframe to Spark DataFrame with Default schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e65ee12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1984 entries, 0 to 185\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Season        0 non-null      float64\n",
      " 1   Sector        1984 non-null   object \n",
      " 2   Category      1984 non-null   object \n",
      " 3   Crop          1984 non-null   object \n",
      " 4   QueryType     1984 non-null   object \n",
      " 5   QueryText     1984 non-null   object \n",
      " 6   KccAns        1984 non-null   object \n",
      " 7   StateName     1984 non-null   object \n",
      " 8   DistrictName  1984 non-null   object \n",
      " 9   BlockName     1984 non-null   object \n",
      " 10  CreatedOn     1984 non-null   object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 186.0+ KB\n",
      "root\n",
      " |-- Season: double (nullable = true)\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Crop: string (nullable = true)\n",
      " |-- QueryType: string (nullable = true)\n",
      " |-- QueryText: string (nullable = true)\n",
      " |-- KccAns: string (nullable = true)\n",
      " |-- StateName: string (nullable = true)\n",
      " |-- DistrictName: string (nullable = true)\n",
      " |-- BlockName: string (nullable = true)\n",
      " |-- CreatedOn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frame.drop_duplicates().info()\n",
    "\n",
    "kccFrame = spark.createDataFrame(frame)\n",
    "kccFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d25c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming kccans with split on '\\n' and crop on '(' \n",
    "\n",
    "kccFrame1 = kccFrame.withColumn(\"kcc\",split(col(\"KccAns\"),\"\\n\",2).getItem(0))\n",
    "kccFrame1 = kccFrame1.withColumn(\"Crops\",split(col(\"Crop\"),\"\\(\",2).getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc58fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Season',\n",
       " 'Sector',\n",
       " 'Category',\n",
       " 'Crop',\n",
       " 'QueryType',\n",
       " 'QueryText',\n",
       " 'KccAns',\n",
       " 'StateName',\n",
       " 'DistrictName',\n",
       " 'BlockName',\n",
       " 'CreatedOn',\n",
       " 'kcc',\n",
       " 'Crops']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = kccFrame1.columns\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b2b07",
   "metadata": {},
   "source": [
    "# Triming spaces and converting all records to lowercase using loop over each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3768f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season..Done\n",
      "Sector..Done\n",
      "Category..Done\n",
      "Crop..Done\n",
      "QueryType..Done\n",
      "QueryText..Done\n",
      "KccAns..Done\n",
      "StateName..Done\n",
      "DistrictName..Done\n",
      "BlockName..Done\n",
      "CreatedOn..Done\n",
      "kcc..Done\n",
      "Crops..Done\n"
     ]
    }
   ],
   "source": [
    "for key in columns_list:\n",
    "    kccFrame1 = kccFrame1.withColumn(key,lower((key)))\n",
    "    kccFrame1 = kccFrame1.withColumn(key,trim(key))\n",
    "    print(key+\"..Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "553cc818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Kcc='cloudy weather, there is a chance of  showers in your area'),\n",
       " Row(Kcc='recommended to spray emamectin benzoate (proclaim) 90 grams /150 -200 litres of water / acre'),\n",
       " Row(Kcc='cloudy weather , chance of showers in your area'),\n",
       " Row(Kcc='మీ ప్రాంతములో వాతావరణం మబ్బులుగా  ఉంటుంది, జల్లులు  పడే అవకాశం ఉంది.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kccFrame1.select(\"Kcc\").take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac81f56",
   "metadata": {},
   "source": [
    "# Splitting column CreatedOn to seperate timeofQuery and Date created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1fe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kccFrame1 = kccFrame1.withColumn(\"createdDate\",split('CreatedOn','t',-1)\\\n",
    "               .getItem(0))\\\n",
    "                .withColumn(\"createdTime\",split('CreatedOn','t',-1)\\\n",
    "                .getItem(1))\\\n",
    "                #.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59a3bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Season: string, Sector: string, Category: string, Crop: string, QueryType: string, QueryText: string, KccAns: string, StateName: string, DistrictName: string, BlockName: string, CreatedOn: string, kcc: string, Crops: string, createdDate: string, createdTime: string, convertedDate: date]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kccFrame1 = kccFrame1.withColumn(\"convertedDate\",to_date(col(\"createdDate\")))\n",
    "kccFrame1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a2e22",
   "metadata": {},
   "source": [
    "# Generating Months,Day,Hour of query created for using pyspark inbuilt datetime functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "295ee063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Season: string, Sector: string, Category: string, Crop: string, QueryType: string, QueryText: string, KccAns: string, StateName: string, DistrictName: string, BlockName: string, CreatedOn: string, kcc: string, Crops: string, createdDate: string, createdTime: string, convertedDate: date, createdMonth: int, createdDay: int, createdHour: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kccFrame1=kccFrame1.withColumn(\"createdMonth\",month('convertedDate'))\\\n",
    ".withColumn(\"createdDay\",dayofmonth('convertedDate'))\\\n",
    ".withColumn(\"createdHour\",hour('createdTime'))\n",
    "\n",
    "kccFrame1.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b54768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "InMemoryTableScan [Season#494, Sector#522, Category#550, Crop#578, QueryType#606, QueryText#634, KccAns#662, StateName#690, DistrictName#718, BlockName#746, CreatedOn#774, kcc#802, Crops#830, createdDate#875, createdTime#891, convertedDate#907, createdMonth#981, createdDay#1001, createdHour#1021]\n",
      "   +- InMemoryRelation [Season#494, Sector#522, Category#550, Crop#578, QueryType#606, QueryText#634, KccAns#662, StateName#690, DistrictName#718, BlockName#746, CreatedOn#774, kcc#802, Crops#830, createdDate#875, createdTime#891, convertedDate#907, createdMonth#981, createdDay#1001, createdHour#1021], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- *(1) Project [trim(lower(trim(lower(cast(Season#66 as string)), None)), None) AS Season#494, trim(lower(trim(lower(Sector#67), None)), None) AS Sector#522, trim(lower(trim(lower(Category#68), None)), None) AS Category#550, trim(lower(trim(lower(Crop#69), None)), None) AS Crop#578, trim(lower(trim(lower(QueryType#70), None)), None) AS QueryType#606, trim(lower(trim(lower(QueryText#71), None)), None) AS QueryText#634, trim(lower(trim(lower(KccAns#72), None)), None) AS KccAns#662, trim(lower(trim(lower(StateName#73), None)), None) AS StateName#690, trim(lower(trim(lower(DistrictName#74), None)), None) AS DistrictName#718, trim(lower(trim(lower(BlockName#75), None)), None) AS BlockName#746, trim(lower(trim(lower(CreatedOn#76), None)), None) AS CreatedOn#774, trim(lower(trim(lower(split(KccAns#72, \n",
      ", 2)[0]), None)), None) AS kcc#802, trim(lower(trim(lower(split(Crop#69, \\(, 2)[0]), None)), None) AS Crops#830, split(trim(lower(trim(lower(CreatedOn#76), None)), None), t, -1)[0] AS createdDate#875, split(trim(lower(trim(lower(CreatedOn#76), None)), None), t, -1)[1] AS createdTime#891, cast(split(trim(lower(trim(lower(CreatedOn#76), None)), None), t, -1)[0] as date) AS convertedDate#907, month(cast(split(trim(lower(trim(lower(CreatedOn#76), None)), None), t, -1)[0] as date)) AS createdMonth#981, dayofmonth(cast(split(trim(lower(trim(lower(CreatedOn#76), None)), None), t, -1)[0] as date)) AS createdDay#1001, hour(cast(split(trim(lower(trim(lower(CreatedOn#76), None)), None), t, -1)[1] as timestamp), Some(Asia/Calcutta)) AS createdHour#1021]\n",
      "            +- *(1) Scan ExistingRDD[Season#66,Sector#67,Category#68,Crop#69,QueryType#70,QueryText#71,KccAns#72,StateName#73,DistrictName#74,BlockName#75,CreatedOn#76]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kccFrame1.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428c11c",
   "metadata": {},
   "source": [
    "# Creating a pyspark regula UDF function for converting few kccans which are in telugu lang to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45659cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTextEng(text):\n",
    "    return GoogleTranslator(source='te', target='en').translate(text)\n",
    "\n",
    "#spark.udf.register(\"convertTextEng\",convertTextEng)  for sql dataframe\n",
    "convertToEng = udf(convertTextEng,StringType()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f162051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kccFrame1 = kccFrame1.withColumn('kccEng',convertToEng('kcc'))\n",
    "\n",
    "kccFrame1 = kccFrame1.drop(\"Season\",\"KccAns\",\"CreatedOn\",\"createdDate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2b53f",
   "metadata": {},
   "source": [
    "# Writing final denormalized table to parquet format with partiotioned by months of kcc generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "178cbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kccFrame1.write.partitionBy(\"createdMonth\").mode(\"overwrite\").parquet(\"kcc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f723ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "parDF1=spark.read.parquet(\"kcc.parquet\")\n",
    "parDF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "97701734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 kcc|              kccEng|\n",
      "+--------------------+--------------------+\n",
      "|cloudy weather, t...|cloudy weather, t...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|cloudy weather , ...|cloudy weather, c...|\n",
      "|మీ ప్రాంతములో వాత...|The weather in yo...|\n",
      "|recommended to do...|Recommended to do...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|cloudy weather , ...|cloudy weather, c...|\n",
      "|echnical name : f...|Technical name : ...|\n",
      "|crop duration : 1...|crop duration : 1...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "|there is chance o...|there is chance o...|\n",
      "|recommended  to s...|recommended to sp...|\n",
      "|మీ ప్రాంతములో వాత...|The weather in yo...|\n",
      "|recommended to co...|recommended to co...|\n",
      "|recommended do no...|recommended do no...|\n",
      "|recommended to sp...|recommended to sp...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parDF1.select(\"kcc\",\"kccEng\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f38e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
