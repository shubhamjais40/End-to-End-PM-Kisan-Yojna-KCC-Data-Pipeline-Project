{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6695ce",
   "metadata": {},
   "source": [
    "# Importing python libs and SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac46fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "import pandas as ps\n",
    "from pyspark.sql.functions import trim,upper,lower,to_date,to_timestamp,transform,split,col\n",
    "from pyspark.sql.functions import dayofmonth,month,hour\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.sql.functions import udf,col\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "spark=SparkSession\\\n",
    "           .builder\\\n",
    "           .appName(\"SparkSQLTransformApp\")\\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa26a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.selfDestruct.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fabad0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\EXTRACTS_RAW\\*.xlsx\n"
     ]
    }
   ],
   "source": [
    "# defining path for extracts raw files and output staging lake\n",
    "\n",
    "EXTRACTSPATH = Path.cwd().parent/\"EXTRACTS_RAW\"/\"*.xlsx\"\n",
    "\n",
    "STAGINGPATH = Path.cwd().parent/\"STAGING_LAKE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86727f07",
   "metadata": {},
   "source": [
    "# Reading extracts raw files from extracts directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a97676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_10extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_11extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_12extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_6extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_7extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_8extracts.xlsx',\n",
       " 'C:\\\\Users\\\\cvb\\\\Documents\\\\automation_python\\\\PM kisan call center query project\\\\project\\\\extracts\\\\2023_9extracts.xlsx']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_list = glob.glob(str(EXTRACTSPATH))\n",
    "\n",
    "#extract_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433aa30",
   "metadata": {},
   "source": [
    "# Reading extracts in chunks and appending all dataframes into empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d5db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_10extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_11extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_12extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_6extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_7extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_8extracts.xlsx appended...\n",
      "C:\\Users\\cvb\\Documents\\automation_python\\PM kisan call center query project\\project\\extracts\\2023_9extracts.xlsx appended...\n"
     ]
    }
   ],
   "source": [
    "frame=ps.DataFrame([])\n",
    "for chunks in extract_list:\n",
    "    df=ps.read_excel(chunks,index_col=None)\n",
    "    frame=frame.append(df)\n",
    "    print(f'{chunks} appended...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e74b9c",
   "metadata": {},
   "source": [
    "# Converting Appended pandas Dataframe to Spark DataFrame with Default schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e65ee12f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-38beb53b6308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkccFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkccFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "frame.drop_duplicates()\n",
    "\n",
    "kccFrame = spark.createDataFrame(frame)\n",
    "kccFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d25c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming kccans with split on '\\n' and crop on '(' \n",
    "\n",
    "kccFrame1 = kccFrame.withColumn(\"kcc\",split(col(\"KccAns\"),\"\\n\",2).getItem(0))\n",
    "kccFrame1 = kccFrame1.withColumn(\"Crops\",split(col(\"Crop\"),\"\\(\",2).getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc58fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Season',\n",
       " 'Sector',\n",
       " 'Category',\n",
       " 'Crop',\n",
       " 'QueryType',\n",
       " 'QueryText',\n",
       " 'KccAns',\n",
       " 'StateName',\n",
       " 'DistrictName',\n",
       " 'BlockName',\n",
       " 'CreatedOn',\n",
       " 'kcc',\n",
       " 'Crops']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = kccFrame1.columns\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b2b07",
   "metadata": {},
   "source": [
    "# Triming spaces and converting all records to lowercase using loop over each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3768f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season..Done\n",
      "Sector..Done\n",
      "Category..Done\n",
      "Crop..Done\n",
      "QueryType..Done\n",
      "QueryText..Done\n",
      "KccAns..Done\n",
      "StateName..Done\n",
      "DistrictName..Done\n",
      "BlockName..Done\n",
      "CreatedOn..Done\n",
      "kcc..Done\n",
      "Crops..Done\n"
     ]
    }
   ],
   "source": [
    "for key in columns_list:\n",
    "    kccFrame1 = kccFrame1.withColumn(key,lower((key)))\n",
    "    kccFrame1 = kccFrame1.withColumn(key,trim(key))\n",
    "    print(key+\"..Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac81f56",
   "metadata": {},
   "source": [
    "# Splitting column CreatedOn to seperate timeofQuery and Date created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1fe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kccFrame1 = kccFrame1.withColumn(\"createdDate\",split('CreatedOn','t',-1)\\\n",
    "               .getItem(0))\\\n",
    "                .withColumn(\"createdTime\",split('CreatedOn','t',-1)\\\n",
    "                .getItem(1))\\\n",
    "                #.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59a3bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Season: string, Sector: string, Category: string, Crop: string, QueryType: string, QueryText: string, KccAns: string, StateName: string, DistrictName: string, BlockName: string, CreatedOn: string, kcc: string, Crops: string, createdDate: string, createdTime: string, convertedDate: date]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kccFrame1 = kccFrame1.withColumn(\"convertedDate\",to_date(col(\"createdDate\")))\n",
    "kccFrame1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a2e22",
   "metadata": {},
   "source": [
    "# Generating Months,Day,Hour of query created for using pyspark inbuilt datetime functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "295ee063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Season: string, Sector: string, Category: string, Crop: string, QueryType: string, QueryText: string, KccAns: string, StateName: string, DistrictName: string, BlockName: string, CreatedOn: string, kcc: string, Crops: string, createdDate: string, createdTime: string, convertedDate: date, createdMonth: int, createdDay: int, createdHour: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kccFrame1=kccFrame1.withColumn(\"createdMonth\",month('convertedDate'))\\\n",
    ".withColumn(\"createdDay\",dayofmonth('convertedDate'))\\\n",
    ".withColumn(\"createdHour\",hour('createdTime'))\n",
    "\n",
    "kccFrame1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428c11c",
   "metadata": {},
   "source": [
    "# Creating a pyspark regula UDF function for converting few kccans which are in telugu lang to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45659cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTextEng(text):\n",
    "    return GoogleTranslator(source='te', target='en').translate(text)\n",
    "\n",
    "#spark.udf.register(\"convertTextEng\",convertTextEng)  for sql dataframe\n",
    "convertToEng = udf(convertTextEng,StringType()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f162051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kccFrame1 = kccFrame1.withColumn('kccEng',convertToEng('kcc'))\n",
    "\n",
    "kccFrame1 = kccFrame1.drop(\"Season\",\"KccAns\",\"CreatedOn\",\"createdDate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2b53f",
   "metadata": {},
   "source": [
    "# Writing final denormalized table to parquet format with partiotioned by months of kcc generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "178cbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kccFrame1.write.partitionBy(\"createdMonth\").mode(\"overwrite\").parquet(str(STAGINGPATH)+\"/kcc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97701734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parDF1.select(\"createdMonth\").distinct().write.parquet(str(STAGINGPATH)+\"/kcc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f38e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
