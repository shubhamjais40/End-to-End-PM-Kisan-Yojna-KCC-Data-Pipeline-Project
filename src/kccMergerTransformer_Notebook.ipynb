{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17aa5316",
   "metadata": {},
   "source": [
    "# Import All Usefule Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3eeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#import pyspark.pandas as pd\n",
    "#import pandas as ps\n",
    "from pyspark.sql.functions import trim,upper,lower,to_date,to_timestamp,transform,split,col,substring\n",
    "from pyspark.sql.functions import dayofmonth,month,hour\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.sql.functions import sum,avg,max,count\n",
    "from pyspark.sql.functions import udf,col\n",
    "from fastavro import reader\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "\n",
    "log = logging.getLogger('test')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "def avro_reader(filename):\n",
    "    with open(filename, 'rb') as fo:\n",
    "        avro_reader = reader(fo)\n",
    "        records = [r for r in avro_reader]\n",
    "        return records\n",
    "\n",
    "\n",
    "sc=SparkSession\\\n",
    "           .builder\\\n",
    "           .appName(\"SparkSQLDenoramlisedApp\")\\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70732b01",
   "metadata": {},
   "source": [
    "# Input & Output Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f3e9f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging path exists\n"
     ]
    }
   ],
   "source": [
    "FILE_TO_TRANSFORM = \"kcc.parquet\"\n",
    "\n",
    "STAGING_PATH = Path.cwd().parent.joinpath(\"STAGING_LAKE\",FILE_TO_TRANSFORM)\n",
    "#print(STAGING_PATH)\n",
    "\n",
    "OUTPUT = Path.cwd().parent.joinpath(\"DOWNSTREAM_READY_EXTRACTS\")\n",
    "\n",
    "PATH_TO_BLOCKS_DF = Path.cwd().parent.joinpath('ARCHIVE','blocks_coordinates.csv')\n",
    "\n",
    "PATH_TO_CALENDER = Path.cwd().parent.joinpath('ARCHIVE','calender_range_20230601_20231231.avro')\n",
    "\n",
    "\n",
    "if STAGING_PATH.exists():\n",
    "    print(\"staging path exists\")\n",
    "else:\n",
    "    log.warning(\"Staging path not exists,need to create\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dce08c",
   "metadata": {},
   "source": [
    "# Reading all required datasets processed after extracts generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b6df6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Crops: string (nullable = true)\n",
      " |-- QueryType: string (nullable = true)\n",
      " |-- StateName: string (nullable = true)\n",
      " |-- DistrictName: string (nullable = true)\n",
      " |-- BlockName: string (nullable = true)\n",
      " |-- QueryText: string (nullable = true)\n",
      " |-- kccEng: string (nullable = true)\n",
      " |-- createdTime: string (nullable = true)\n",
      " |-- convertedDate: date (nullable = true)\n",
      " |-- createdHour: integer (nullable = true)\n",
      "\n",
      "+-----------+--------+----------+------------------+--------------+-------------+----------+--------------------+--------------------+-----------+-------------+-----------+\n",
      "|     Sector|Category|     Crops|         QueryType|     StateName| DistrictName| BlockName|           QueryText|              kccEng|createdTime|convertedDate|createdHour|\n",
      "+-----------+--------+----------+------------------+--------------+-------------+----------+--------------------+--------------------+-----------+-------------+-----------+\n",
      "|agriculture| cereals|     paddy|           weather|andhra pradesh|east godavari|peddapuram|farmer asked quer...|cloudy weather, t...|07:45:59.37|   2023-10-01|          7|\n",
      "|agriculture|  pulses|black gram|\tplant protection\t|andhra pradesh|east godavari|peddapuram|farmer asked quer...|recommended to sp...|07:49:57.94|   2023-10-01|          7|\n",
      "|agriculture|  others|black gram|           weather|andhra pradesh|east godavari|peddapuram|farmer asked quer...|cloudy weather, c...|07:50:49.89|   2023-10-01|          7|\n",
      "+-----------+--------+----------+------------------+--------------+-------------+----------+--------------------+--------------------+-----------+-------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kccDF = sc.read.parquet(str(STAGING_PATH)+\"/kcc.parquet\").select('Sector','Category','Crops','QueryType','StateName','DistrictName','BlockName','QueryText','kccEng','createdTime','convertedDate','createdHour')\n",
    "kccDF.printSchema()\n",
    "\n",
    "kccDF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e516b7",
   "metadata": {},
   "source": [
    "# Checking for any Null Values in KccDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64adf476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Null Values in either Data Entities\n"
     ]
    }
   ],
   "source": [
    "#Checking kccDF if any timestamp is null ,Block if null ,if  Crop, QueryText is null,\n",
    "null_count = kccDF.where(kccDF.createdTime.isNull() | kccDF.BlockName.isNull() | kccDF.Crops.isNull() | kccDF.QueryText.isNull()).count()\n",
    "\n",
    "if null_count == 0:\n",
    "    print(\"No Null Values in either Data Entities\")\n",
    "else:\n",
    "    print(\"Null Values found \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6014289",
   "metadata": {},
   "source": [
    "# Reading Blocks Cordinates Data with BlockName should be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "995f2062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------+\n",
      "|      blocks|          latitude|        longitude|\n",
      "+------------+------------------+-----------------+\n",
      "|  PEDDAPURAM|       17.09813605|82.13236972772236|\n",
      "| ATREYAPURAM|16.853765199999998|81.78261498987507|\n",
      "|  RANGAMPETA|       17.05134845|81.99740312853817|\n",
      "|MUMMIDIVARAM|16.646411450000002|82.11641830975093|\n",
      "|    KAJULURU|        16.7973104|82.15952482953708|\n",
      "+------------+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blockDF = sc.read.format('csv').option('inferSchema',True).option('header',True).load(str(PATH_TO_BLOCKS_DF))\n",
    "\n",
    "#Renaming BlockName to avoid ambiguous conlficts between kccDF & blockDF \n",
    "blockDF = blockDF.withColumnRenamed(\"BlockName\",\"blocks\")\n",
    "#removing duplicates\n",
    "blockDF_unique = blockDF.dropDuplicates(['blocks'])\n",
    "\n",
    "#avoid if file appended with header:true while generating blocks coordinates\n",
    "blockDFValid = blockDF_unique.where('blocks !=\"BlockName\"')\n",
    "#blockDF.printSchema()\n",
    "\n",
    "#blockDFValid.count()\n",
    "blockDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da0042e",
   "metadata": {},
   "source": [
    "# Testing Data Validity For block coordinates DF:blockDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04b7c905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could contain duplicate values or heading appended multiple Times\n",
      "WARNING:root:Lengths are different\n",
      "\tExpected : 56\n",
      "\tActual   : 113\n",
      "INFO:test:\n",
      " blockDFValid is cleaned \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check if any block name is null\n",
    "#blockDFValid.where(blockDFValid.blocks.isNull()).collect()\n",
    "from pyspark_assert import assert_frame_equal\n",
    "\n",
    "try:\n",
    "    assert_frame_equal(blockDF, blockDFValid)\n",
    "except Exception as e:\n",
    "    logging.warning('Could contain duplicate values or heading appended multiple Times')\n",
    "    logging.warning(e)\n",
    "    \n",
    "finally:\n",
    "    log.info('\\n blockDFValid is cleaned ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6863b",
   "metadata": {},
   "source": [
    "# Reading Calender Data for range inclusive of kccDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2681683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MonthName: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- quarter: long (nullable = true)\n",
      " |-- weekName: string (nullable = true)\n",
      " |-- weekday: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:test:214\n"
     ]
    }
   ],
   "source": [
    "calender_dic = avro_reader(str(PATH_TO_CALENDER))\n",
    "calenderDF = sc.createDataFrame(calender_dic).drop_duplicates(['date'])\n",
    "calenderDF.printSchema()\n",
    "log.debug(calenderDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "73407397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+---+-----+-------+---------+-------+----------+\n",
      "|MonthName|               date|day|month|quarter| weekName|weekday|  datePart|\n",
      "+---------+-------------------+---+-----+-------+---------+-------+----------+\n",
      "|     June|2023-06-14T00:00:00| 14|    6|      2|Wednesday|      2|2023-06-14|\n",
      "|September|2023-09-22T00:00:00| 22|    9|      3|   Friday|      4|2023-09-22|\n",
      "|     June|2023-06-27T00:00:00| 27|    6|      2|  Tuesday|      1|2023-06-27|\n",
      "|September|2023-09-16T00:00:00| 16|    9|      3| Saturday|      5|2023-09-16|\n",
      "+---------+-------------------+---+-----+-------+---------+-------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calenderDF = calenderDF.withColumn(\"datePart\",substring(col(\"date\"),1,10))\n",
    "calenderDF.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea64368",
   "metadata": {},
   "source": [
    "# Merging/Joining all imported DataSets with Star Schema Data Modeling concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "079db832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Crops: string (nullable = true)\n",
      " |-- QueryType: string (nullable = true)\n",
      " |-- StateName: string (nullable = true)\n",
      " |-- DistrictName: string (nullable = true)\n",
      " |-- BlockName: string (nullable = true)\n",
      " |-- QueryText: string (nullable = true)\n",
      " |-- kccEng: string (nullable = true)\n",
      " |-- createdTime: string (nullable = true)\n",
      " |-- convertedDate: date (nullable = true)\n",
      " |-- createdHour: integer (nullable = true)\n",
      " |-- blocks: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- MonthName: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- month: long (nullable = true)\n",
      " |-- quarter: long (nullable = true)\n",
      " |-- weekName: string (nullable = true)\n",
      " |-- weekday: long (nullable = true)\n",
      " |-- datePart: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergedKccDF = kccDF.join(blockDFValid,kccDF.BlockName ==  lower(blockDFValid.blocks),\"left\")\\\n",
    "        .join(calenderDF,kccDF.convertedDate.cast(StringType()) == calenderDF.datePart,\"left\")\n",
    "\n",
    "mergedKccDF.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fba48c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "kccMergedDF = mergedKccDF.select('Sector','Category','Crops','QueryType','QueryText','kccEng','StateName','DistrictName','blocks','latitude','longitude','convertedDate','day','month','MonthName','quarter','weekName','weekDay','year')\n",
    "\n",
    "kccMergedDF.write.partitionBy('MonthName','Sector').mode('errorifexists').parquet('kccFinalDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd0074",
   "metadata": {},
   "source": [
    "# Reporting for Data Quality and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c78470cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kccMergedDF.createOrReplaceTempView(\"kccModeltb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3b77149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='kccmodeltb', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9b6171d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|MonthName|Total_Created_Query|\n",
      "+---------+-------------------+\n",
      "| November|                475|\n",
      "| December|                428|\n",
      "|  October|                280|\n",
      "|     July|                215|\n",
      "|   August|                206|\n",
      "|     June|                206|\n",
      "|September|                186|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Monthly_created_Query_Rep = kccMergedDF.groupby('MonthName')\\\n",
    "        .agg({'QueryText':'count','Crops':'count'})\\\n",
    "        .select('MonthName',col('count(Crops)')\\\n",
    "        .alias('Total_Created_Query'))\\\n",
    "        .sort(col('Total_Created_Query').desc())\\\n",
    "        #.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "07826841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------------+------------+\n",
      "|MonthName|agriculture|animal husbandry|horticulture|\n",
      "+---------+-----------+----------------+------------+\n",
      "|     July|        169|            null|          46|\n",
      "| November|        425|               5|          45|\n",
      "|  October|        239|               2|          39|\n",
      "|   August|        166|               2|          38|\n",
      "|     June|        173|               2|          31|\n",
      "| December|        358|               1|          69|\n",
      "|September|        142|            null|          44|\n",
      "+---------+-----------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SectorQueryReport = kccMergedDF.groupby('MonthName')\\\n",
    "                    .pivot('Sector')\\\n",
    "                    .agg({\"MonthName\": \"count\"})\n",
    "\n",
    "SectorQueryReport.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e5fa266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|MonthName|     Crops|Query_count|\n",
      "+---------+----------+-----------+\n",
      "|September|    others|         58|\n",
      "| November|    tomato|          1|\n",
      "| November|     grape|          4|\n",
      "|     June|    bovine|          2|\n",
      "|   August|betel vine|          1|\n",
      "|  October|   brinjal|          8|\n",
      "| November|     maize|         34|\n",
      "|September|    bhindi|          1|\n",
      "| December|     mango|          4|\n",
      "|  October|    others|         47|\n",
      "|September|    orange|          2|\n",
      "|  October|    papaya|          2|\n",
      "| November|    papaya|          1|\n",
      "|  October|green gram|          2|\n",
      "|     July|  oil palm|          2|\n",
      "| December|     paddy|        194|\n",
      "|  October|       pig|          1|\n",
      "|  October|    bhindi|          1|\n",
      "|   August|    papaya|          1|\n",
      "|     June| carnation|          1|\n",
      "+---------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kccMergedDF.groupby('MonthName','Crops').agg(count(kccMergedDF.Crops).alias('Query_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "78725f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+-----------+----+\n",
      "|month|MonthName|     Crops|query_count|top3|\n",
      "+-----+---------+----------+-----------+----+\n",
      "|    6|     June|    others|         79|   1|\n",
      "|    6|     June|     paddy|         70|   2|\n",
      "|    6|     June|     maize|          7|   3|\n",
      "|    7|     July|     paddy|         79|   1|\n",
      "|    7|     July|    others|         73|   2|\n",
      "|    7|     July|    cotton|          8|   3|\n",
      "|    8|   August|     paddy|         84|   1|\n",
      "|    8|   August|    others|         51|   2|\n",
      "|    8|   August|black gram|         14|   3|\n",
      "|    9|September|     paddy|         50|   2|\n",
      "|    9|September|    others|         58|   1|\n",
      "|    9|September|black gram|         16|   3|\n",
      "|   10|  October|     paddy|         97|   1|\n",
      "|   10|  October|    others|         47|   3|\n",
      "|   10|  October|black gram|         49|   2|\n",
      "|   11| November|     maize|         34|   3|\n",
      "|   11| November|     paddy|        231|   1|\n",
      "|   11| November|    others|        123|   2|\n",
      "|   12| December|     paddy|        194|   1|\n",
      "|   12| December|    others|        130|   2|\n",
      "+-----+---------+----------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc.sql(\"with tmp as \\\n",
    "        (select month,MonthName,Crops,count(querytext) as query_count from kccModeltb \\\n",
    "        group by month,MonthName,Crops order by MonthName) \\\n",
    "        select *, Rank() over(partition by MonthName order by query_count desc) top3 from tmp\")\\\n",
    "        .filter('top3 < 4').sort(col('month')).show()\n",
    "#from pyspark.sql import Window\n",
    "\n",
    "#window = Window.partitionBy(\"month\").orderBy(\"Query_count\")\n",
    "#kccMergedDF.groupby('MonthName','Crops').agg(count(kccMergedDF.Crops).alias('Query_count')).withColumn(\"rank\", func.sum(\"id\").over(window)).sort(\"month\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec33f3",
   "metadata": {},
   "source": [
    "#kccMergedDF.createOrReplaceTempView(\"kccModeltb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9c5c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import expr,length\n",
    "#sc.sql(\"select convertedDate from emp order by convertedDate limit 3\").write.option(\"header\",True).mode(\"append\").csv(\"DQ_REPORT\\ss\")\n",
    "\n",
    "#dd.write.csv(name, format='csv', mode='append', partitionBy=None, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "92613de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.sql(\"select min(convertedDate),max(convertedDate),count(distinct(convertedDate)) AS UNIQUE_DAYS from emp\")\\\n",
    "#.write.option(\"header\",True).mode(\"append\").csv(\"DQ_REPORT\\CALENDER_REPORT\")\n",
    "#.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ce642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
